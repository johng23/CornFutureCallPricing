{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "f5db0ae0eb3ed28a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:02.739204Z",
     "start_time": "2025-11-07T01:15:01.929136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import yfinance as yf\n",
    "from src.data.preprocess import extend_market_data\n",
    "import src.data.weather_script as ws\n",
    "import pandas as pd\n",
    "import os\n",
    "from src.data import helper\n",
    "from arch import arch_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n"
   ],
   "id": "18f6648d621a5337",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading and preprocessing",
   "id": "7e628f67bdb7bae0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Unfortunately, we only have rolling futures data, though preferably we'd get, say, only the futures contract expiring in a specific month.",
   "id": "bf67b64126c51ca3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:03.480831Z",
     "start_time": "2025-11-07T01:15:02.744449Z"
    }
   },
   "source": [
    "# Define ticker symbols for corn futures\n",
    "corn_ticker = \"ZC=F\"   # Corn Futures (rolling)\n",
    "corn = yf.Ticker(corn_ticker)\n",
    "corn_data = corn.history(start =\"2019-01-01\", end=\"2025-10-31\")\n",
    "\n",
    "corn_data = extend_market_data(corn_data)\n",
    "\n",
    "features = list(corn_data.columns)\n",
    "features.remove('expiry')\n",
    "corn_data = corn_data[features]\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:03.488895Z",
     "start_time": "2025-11-07T01:15:03.485858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Defining column names for weather features\n",
    "weather_features = [\n",
    "       'average_temperature_distribution_weighted_mean',\n",
    "       'average_temperature_distribution_weighted_variance',\n",
    "       'average_temperature_distribution_weighted_std',\n",
    "       'average_temperature_distribution_weighted_skewness',\n",
    "       'average_temperature_distribution_weighted_kurtosis',\n",
    "       'average_temperature_distribution_weighted_median',\n",
    "       'average_temperature_distribution_min_value',\n",
    "       'average_temperature_distribution_max_value',\n",
    "       'maximum_temperature_distribution_weighted_mean',\n",
    "       'maximum_temperature_distribution_weighted_variance',\n",
    "       'maximum_temperature_distribution_weighted_std',\n",
    "       'maximum_temperature_distribution_weighted_skewness',\n",
    "       'maximum_temperature_distribution_weighted_kurtosis',\n",
    "       'maximum_temperature_distribution_weighted_median',\n",
    "       'maximum_temperature_distribution_min_value',\n",
    "       'maximum_temperature_distribution_max_value',\n",
    "       'minimum_temperature_distribution_weighted_mean',\n",
    "       'minimum_temperature_distribution_weighted_variance',\n",
    "       'minimum_temperature_distribution_weighted_std',\n",
    "       'minimum_temperature_distribution_weighted_skewness',\n",
    "       'minimum_temperature_distribution_weighted_kurtosis',\n",
    "       'minimum_temperature_distribution_weighted_median',\n",
    "       'minimum_temperature_distribution_min_value',\n",
    "       'minimum_temperature_distribution_max_value',\n",
    "       'precipitation_distribution_weighted_mean',\n",
    "       'precipitation_distribution_weighted_variance',\n",
    "       'precipitation_distribution_weighted_std',\n",
    "       'precipitation_distribution_weighted_median',\n",
    "       'precipitation_distribution_min_value',\n",
    "       'precipitation_distribution_max_value',\n",
    "       'snow_distribution_weighted_mean',\n",
    "       'snow_distribution_weighted_variance', 'snow_distribution_weighted_std',\n",
    "       'snow_distribution_weighted_median', 'snow_distribution_min_value',\n",
    "       'snow_distribution_max_value']"
   ],
   "id": "db26c0d1605d135a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Obtaining weather data if it exists in the directory. Otherwise, creates the weather data.\n",
    "cadot is a nested dictionary with the following structure:\n",
    "\n",
    "dates -- climate tuples (avg temperature, min temperature, max temperature, precipitation, snow) -- amount of corn crop area with this climate tuple on a given date\n",
    "\n",
    "This distribution has a lot of data, but we make several projections, and our weather_df will be indexed by dates, and will contain the weighted (by crop area) average, std, and other statistics of each of the 5 climate data.\n",
    "\n",
    "### Requires cropland layer file downloaded from [USDA](https://www.nass.usda.gov/Research_and_Science/Cropland/Release/index.php) + preprocessing"
   ],
   "id": "4fd84a161f3637fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:03.514972Z",
     "start_time": "2025-11-07T01:15:03.501338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weather_path = \"../cached_weather.pkl\"\n",
    "if os.path.exists(weather_path):\n",
    "    weather_df = pd.read_pickle(weather_path)\n",
    "else:\n",
    "    cadot_path = \"../cached_cadot\"\n",
    "    if os.path.exists(cadot_path):\n",
    "        cadot = ws.load_cadot_by_date()\n",
    "    else:\n",
    "        m = 200\n",
    "        cropValue = 1\n",
    "        BAP = ws.bigArrayParser(\"../data/2023_30m_cdls.tif\", m, cropValue)\n",
    "        k = 10\n",
    "        r = 7\n",
    "        cadot = BAP.get_area_with_climate(k, r, m, [\"IA\", \"IL\", \"IN\", \"MO\", \"SD\", \"KS\", \"MN\"], \"2019-01-01\", \"2025-10-31\")\n",
    "        ws.save_cadot_by_date(cadot)\n",
    "    proj = ws.get_projections_multithreaded(cadot)\n",
    "    weather_df = pd.DataFrame(ws.get_weather_features_multithreaded(proj)).transpose()\n",
    "    weather_df.to_pickle(weather_path)\n",
    "\n",
    "weather_df.index = pd.to_datetime(weather_df.index, format='%Y:%m:%d %H:%M:%S')\n",
    "all_data = corn_data.join(weather_df, how='left')\n"
   ],
   "id": "e49c66f04ab4db84",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since the futures data is rolling, we need to clear the log return on days when the contract switches. We will lose some data, but it's only a few days.",
   "id": "b82f4fa750563434"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:03.527975Z",
     "start_time": "2025-11-07T01:15:03.519588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_data_cleaned = all_data.copy()\n",
    "all_data_cleaned.loc[(all_data_cleaned['DTE'] == 0).shift(1, fill_value=False), 'Log_Return'] = 0\n",
    "all_data_cleaned = all_data_cleaned[-360:]"
   ],
   "id": "c6a69fcda5808fc6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Training\n",
    "\n",
    "Our goal will be to predict future volatilities, and use it to generate paths instead of assuming constant volatility as in Black-Scholes. We will do this in the following way.\n",
    "\n",
    "1. We first fit a GARCH(1,1) volatility model.\n",
    "2. We use a linear model and use the weather data to fit the residuals of the volatility model. (Specifically, we look at the predicted volatility of fitted GARCH(1,1) vs the square of log return"
   ],
   "id": "9115e5d9cc6a3e2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:03.575676Z",
     "start_time": "2025-11-07T01:15:03.534187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit GARCH(1,1) model\n",
    "garch_model = arch_model(all_data_cleaned['Log_Return'].dropna(), vol='GARCH', p=1, q=1)\n",
    "garch_results = garch_model.fit(disp='off')\n",
    "\n",
    "# Get the predicted variance from the GARCH model\n",
    "predicted_volatility = garch_results.conditional_volatility**2\n",
    "\n",
    "# Calculate the GARCH model's residuals\n",
    "realized_volatility = all_data_cleaned['Log_Return']**2\n",
    "garch_error = realized_volatility - predicted_volatility\n",
    "\n",
    "# Defining residual model\n",
    "X_weather = all_data_cleaned[weather_features].shift(1)\n",
    "y_error = garch_error[1:]\n",
    "y_error, X_weather = y_error.align(X_weather, join='inner')\n",
    "X_weather = X_weather.loc[y_error.index] # Ensure indices match after potential drops\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', xgb.XGBRegressor())\n",
    "])\n",
    "\n",
    "# Fitting residual model\n",
    "best_error_model = pipeline.fit(X_weather, y_error)"
   ],
   "id": "1bdb1174a2f0e7de",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\ErdosQuantFinance\\Lib\\site-packages\\arch\\univariate\\base.py:694: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.0001474. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 100 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  self._check_scale(resids)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# GBM paths and call value approximation\n",
    "\n",
    "With our fitted GARCH(1,1) model + residual model, we do the following\n",
    "\n",
    "1. We gather volatility paths using the GARCH(1,1) process on the last date in the yfinance data.\n",
    "2. We use the residual model + historical weather data to predict the effects of weather on future volatilities.\n",
    "3. We use these volatility paths to generate price paths for futures\n",
    "4. We use the Longstaff-Schwartz algorithm for pricing an American call option, and estimate the price of a call on the future."
   ],
   "id": "d5cf2d2c0cd352f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:03.588633Z",
     "start_time": "2025-11-07T01:15:03.581576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Variables\n",
    "today_date = pd.to_datetime('today')\n",
    "expiration_date = pd.to_datetime('2026-02-20') # Example expiration\n",
    "business_days = pd.bdate_range(start=today_date, end=expiration_date)\n",
    "days_to_expiration = len(business_days) # trading days until expiration for call option expiring on 2/20/26 for a March '26 futures contract\n",
    "\n",
    "t = 106/252 # trading days\n",
    "K = 440 # strike price\n",
    "n_sims = 100000\n",
    "n_steps = days_to_expiration"
   ],
   "id": "2ecdc2b30318708f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:39.944041Z",
     "start_time": "2025-11-07T01:15:39.815651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "march_corn_ticker = \"ZCH26.CBT\"   # Corn Futures (expiring March '26)\n",
    "march_corn = yf.Ticker(march_corn_ticker)\n",
    "march_corn_data = march_corn.history(start =\"2024-10-01\")\n",
    "march_corn_data = extend_market_data(march_corn_data)\n",
    "features = list(march_corn_data.columns)\n",
    "features.remove('expiry')\n",
    "march_corn_data = march_corn_data[features]\n",
    "last_volatility = march_corn_data['Log_Return'][1:].std() * (252 ** (1/2))\n",
    "risk_free_rate = 0.0380 # risk free rate from https://fred.stlouisfed.org/series/DTB3\n",
    "start_index_position = all_data_cleaned.index.get_indexer([today_date - datetime.timedelta(days=730)], method='nearest')[0]\n",
    "previous_weather = all_data_cleaned.iloc[start_index_position : start_index_position + days_to_expiration][weather_features]\n",
    "S0 = march_corn_data['Close'].iloc[-1]"
   ],
   "id": "5aa6e0bb371007ed",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that garch_results and best_error_model are models for *daily* volatility, whereas the input initial volatility is the historical yearly volatility.",
   "id": "6b47ad5fda344d08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:41.687836Z",
     "start_time": "2025-11-07T01:15:41.154566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vol_path, shocks = helper.simulate_hybrid_vol_paths(garch_results,\n",
    "                                                    best_error_model,\n",
    "                                                    last_volatility, t, n_sims, n_steps,\n",
    "                                                    previous_weather)\n",
    "paths = helper.GBM_paths_with_volatility_paths(S0, risk_free_rate, t, vol_path, shocks)\n",
    "Ct_model = LinearRegression()\n"
   ],
   "id": "2360be24d339621",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comparison to baseline\n",
    "\n",
    "Our baseline model will be a Black-Scholes model with volatility obtained from the historical (last year) volatility, and we also have actual prices for calls from [barchart](https://www.barchart.com/futures/quotes/ZCH26/options/mar-26?futuresOptionsView=merged).\n",
    "\n",
    "Currently (as of 11/06/25), the price of the call option for a futures contract for 5000 bushels of corn is $800. Thus, with our pricing model, we likely have vastly overestimated the price, since we don't expect the premium to be so high. On the other hand, just using Black-Scholes with historical volatility overestimates the price, especially considering that Black-Scholes should estimate the fair market value, without considering premiums."
   ],
   "id": "1bec3f43479d5e5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T01:15:42.363877Z",
     "start_time": "2025-11-07T01:15:42.045743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"The estimated price of the call option for a futures contract for 5000 bushels of corn at strike price ${K:.2f} is ${5000 / 100 * helper.LS_algorithm_call(paths, K, Ct_model):.2f}.\")\n",
    "\n",
    "print(f\"The estimated price (using Black-Scholes) of the call option for a futures contract for 5000 bushels of corn at strike price ${K:.2f} is ${5000 / 100 * helper.bs_call(S0, K, last_volatility, t, risk_free_rate):.2f}.\")"
   ],
   "id": "1ecdb0e6103c7f24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated price of the call option for a futures contract for 5000 bushels of corn at strike price $440.00 is $1319.43.\n",
      "The estimated price (using Black-Scholes) of the call option for a futures contract for 5000 bushels of corn at strike price $440.00 is $1031.32.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "The current model, as it is, is not performant and overestimates the price of the call. There are a few likely sources of error:\n",
    "1. Rolling future data do not extrapolate to a single future data. That is, the volatilities for different future contracts behave differently, especially when it is more than 3 months out.\n",
    "2. The GARCH(1,1) model simply doesn't fit the volatilities well.\n",
    "3. The way the weather data was used is too crude, and there could be more information to be extracted from it.\n",
    "\n",
    "# Future Work\n",
    "\n",
    "1. We may consider other commodities with more data on its historical prices.\n",
    "2. We may expand our weather model, and obtain more features from the distribution of weather.\n",
    "3. We may consider a GARCH-x model, where the exogenous data feeds directly into the volatility model, instead of just modeling the residuals."
   ],
   "id": "eda804a3140a097a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b4b6a467331c2f55"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
